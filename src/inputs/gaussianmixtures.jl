"""
    GaussianMixtureModel(
        data::DataFrame,
        number_components::Integer;
        maximum_iterations::Integer=100,
        tolerance::Number=1e-4,
    )

Fits a Gaussian mixture model to the given data using the Expectation-Maximization (EM) algorithm.

# Arguments
- `data::DataFrame`: The input data as a DataFrame, where each column represents a variable.
- `number_components::Integer`: The number of Gaussian components to fit.
- `maximum_iterations::Integer=100`: (Optional) The maximum number of EM iterations. Default is 100.
- `tolerance::Number=1e-4`: (Optional) The convergence tolerance for the EM algorithm. Default is 1e-4.

# Returns
- `JointDistribution`: A joint distribution object representing the fitted Gaussian mixture model, with variable names corresponding to the columns of `data`.

See also: [`JointDistribution`](@ref)

"""
function GaussianMixtureModel(
    data::DataFrame,
    number_components::Integer;
    maximum_iterations::Integer=100,
    tolerance::Number=1e-4,
)
    # Fit mixture model to the data using EM algorithm
    mixture = _gaussian_mixture_expectation_maximization(
        number_components,
        Matrix(data);
        maximum_iterations=maximum_iterations,
        tolerance=tolerance,
    )

    return JointDistribution(mixture, Symbol.(names(data)))
end

function _gaussian_mixture_expectation_maximization(
    number_components::Integer,
    data::Matrix;
    maximum_iterations::Integer=100,
    tolerance::Number=1e-4,
)
    # Check inputs
    if number_components <= 0
        throw(ArgumentError("Number of components must be a positive integer."))
    end
    if size(data, 2) < 2
        throw(ArgumentError("Input must be at least two-dimensional to fit GMM."))
    end

    # Initialize parameters
    number_samples, _ = size(data)
    Î¼, Î£, Ï€ = _initialize_gaussian_mixture_model(data, number_components)
    log_likelihood_old = -Inf

    for _ in 1:maximum_iterations
        Î³ = _expectation_step(data, Î¼, Î£, Ï€)
        Î¼, Î£, Ï€ = _maximization_step(data, Î³)

        # Log-likelihood (for convergence check)
        log_likelihood = sum(
            log(
                sum(
                    Ï€[k] * pdf(MvNormal(Î¼[k, :], Î£[k]), data[i, :]) for
                    k in 1:number_components
                ),
            ) for i in 1:number_samples
        )

        abs(log_likelihood - log_likelihood_old) < tolerance ? break : continue
        log_likelihood_old = log_likelihood
    end

    return MixtureModel([MvNormal(Î¼[k, :], Î£[k]) for k in 1:number_components], Ï€)
end

function _initialize_gaussian_mixture_model(
    data::Matrix{Float64}, number_components::Integer
)
    # Randomly initialize parameters for GMM
    number_samples, dimensions = size(data)
    Î¼ = data[rand(1:number_samples, number_components), :]  # random initialization of means
    Î£ = [I(dimensions) for _ in 1:number_components]        # identity covariance matrices
    Ï€ = fill(1 / number_components, number_components)      # equal mixing weights
    return Î¼, Î£, Ï€
end

function _expectation_step(
    data::Matrix{Float64}, Î¼::Matrix{Float64}, Î£::Vector, Ï€::Vector{Float64}
)
    number_samples, number_components = size(data, 1), length(Ï€)
    # Compute responsibilities and normalize
    Î³ = [
        Ï€[k] * pdf(MvNormal(Î¼[k, :], Î£[k]), data[i, :]) for i in 1:number_samples,
        k in 1:number_components
    ]
    Î³ = Î³ ./ sum(Î³; dims=2)
    return Î³
end

function _maximization_step(data::Matrix{Float64}, Î³::Matrix{Float64})
    number_samples, dimensions = size(data)
    number_components = size(Î³, 2)
    Nâ‚– = sum(Î³; dims=1)             # effective number of points in cluster ð‘˜
    Ï€ = vec(Nâ‚– ./ number_samples)   # weights: relative number of points in each cluster
    Î¼ = Î³' * data ./ Nâ‚–'            # means: weighted average of points in each cluster
    Î£ = Vector{Matrix{Float64}}(undef, number_components)
    for k in 1:number_components
        data_centered = data .- Î¼[k:k, :]
        Î£â‚– = zeros(dimensions, dimensions)
        for i in 1:number_samples
            Î£â‚– += Î³[i, k] * (data_centered[i, :] * data_centered[i, :]')
        end
        Î£[k] = Î£â‚– / Nâ‚–[k]
    end
    return Î¼, Î£, Ï€
end
